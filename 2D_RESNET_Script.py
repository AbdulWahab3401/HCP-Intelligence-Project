# -*- coding: utf-8 -*-
"""2D RESNET script.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1gr7lbKotIb6Y3XJg9Ju8p9SB9ya6x_Hf
"""

from psutil import virtual_memory
ram_gb = virtual_memory().total / 1e9
print('Your runtime has {:.1f} gigabytes of available RAM\n'.format(ram_gb))

if ram_gb < 20:
  print('Not using a high-RAM runtime')
else:
  print('You are using a high-RAM runtime!')

gpu_info = !nvidia-smi
gpu_info = '\n'.join(gpu_info)
if gpu_info.find('failed') >= 0:
  print('Not connected to a GPU')
else:
  print(gpu_info)

from google.colab import drive
drive.mount('/content/drive')

import torch
# will allow network to run on GPU
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
torch.cuda.empty_cache()
print(device)

# CLASSES FOR DATASETS
import torch
import torchvision
from torch.utils.data import Dataset, DataLoader
import numpy as np
import math
import time
import pandas as pd
import matplotlib.pyplot as plt

import cv2
import albumentations
import albumentations.pytorch
from torchvision import transforms
from PIL import Image

import torch
import torch.nn as nn
import torch.nn.functional as F #contains some useful functions like activation functions & convolution operations you can use

from torchvision import datasets, models, transforms

class TTVDataset(Dataset):

    def __init__(self, ttv , fold , features , transform=None):
        ''' 
        fold: 1,2,3,4 or 5.
        
        features: 1 to 110 : How many fMRI signals should be loaded in.

        ttv:
            0 = train
            1 = test
            2 = valid
        '''

        self.transform = transform
        
        self.features = features
        
        # Path to folder containing all 2D images.
        # self.x_dir = '/content/drive/MyDrive/Colab Notebooks/2D CNN projections/All 2D Image Data/'
        self.x_dir = '/content/drive/MyDrive/Colab Notebooks/2D CNN projections/2D LR Vert_comb Data/'

        # Initialize data, download, etc.
        # spreadsheet = '/content/drive/MyDrive/Colab Notebooks/2D CNN projections/2D Images Filenames.xlsx'
        spreadsheet = '/content/drive/MyDrive/Colab Notebooks/2D CNN projections/2D LR Vert_comb.xlsx'
        
        df = pd.read_excel(io=spreadsheet, sheet_name = fold)

        ssdata = df.to_numpy()
        
        if ttv == 0:
            self.X_names = ssdata[:,0]
            self.y_val = ssdata[:,1]
        
        if ttv == 1:
            self.X_names = ssdata[:,2]
            self.y_val = ssdata[:,3]
        
        if ttv == 2:
            self.X_names = ssdata[:,4]
            self.y_val = ssdata[:,5]
            
        
        # REMOVING NAN VALUES AT END OF LISTS OF STRINGS
        self.X_names = [item for item in self.X_names if str(item) != 'nan']
        self.y_val = [item for item in self.y_val if str(item) != 'nan']
        
        # REMOVING \ufeff FROM THE DATA
        for i in range(len(self.X_names)):
            
            if '\ufeff' in self.X_names[i]:
                self.X_names[i] = self.X_names[i].replace('\ufeff','')
                
            if '\ufeff' in str(self.y_val[i]):
                self.y_val[i] = self.y_val[i].replace('\ufeff','')
        

    # support indexing such that dataset[i] can be used to get i-th sample
    def __getitem__(self, index):
        
        x_subj_path = self.x_dir + self.X_names[index]
        
        self.x_subj = np.load(x_subj_path)
        # self.x_subj = cv2.imread(x_subj_path)
        self.y_subj = self.y_val[index]
        
        # Selecting up to a certain number of features.
        self.x_subj = self.x_subj[:,:,:self.features]
        # print('\n Shape of x_subj: ', self.x_subj.shape)

        # self.x_subj = self.x_subj.reshape(self.features,240,320)

        self.y_subj = np.array(self.y_subj, dtype = int)
        # print('\n Shape of y_subj: ', self.y_subj.shape)

        # Converting to torch tensors.
        self.x_subj = torch.from_numpy(self.x_subj).float()
        self.y_subj = torch.from_numpy(self.y_subj.reshape(-1)).float()
        
        # Changing shape from [240,320,features] to [features,240,320] 
        # self.x_subj = self.x_subj.view(self.features,240,320)
        self.x_subj = self.x_subj.view(self.features,480,320)

        # self.x_subj = self.x_subj.permute(2,0,1)



        start_t = time.time()
        if self.transform:
            self.x_subj = np.array(self.x_subj)
            image = self.x_subj
             
            augmented = self.transform(image=image) 
            image = augmented['image']
            total_time = (time.time() - start_t)

            image = image.reshape(self.features,240,320)
            return image , self.y_subj , total_time


        return self.x_subj , self.y_subj 
        


    # Call len(dataset) to return the size
    def __len__(self):
        # return self.n_samples
        return (len(self.X_names))

# # Same transform with torchvision_transform
# albumentations_transform = albumentations.Compose([
#     albumentations.ElasticTransform(),
    
#     # albumentations.Resize(200, 200), 
#     # albumentations.RandomCrop(100, 100),
#     # albumentations.HorizontalFlip(), # Same with transforms.RandomHorizontalFlip()
#     albumentations.pytorch.transforms.ToTensor()
# ])
# albumentations_transform = TTVDataset(ttv = 1 , fold = 1 ,features = 100, transform = albumentations_transform)

# train_loader = torch.utils.data.DataLoader(albumentations_transform, batch_size = 4 , shuffle = True)

# total_time = 0
# for i, (sample, label) in enumerate(train_loader, 0):
#   print(i)
# # for i in range(100):
#   # sample, label , transform_time = train_loader[i]
#   total_time += transform_time

# print("albumentations time/sample: {} ms".format(total_time*10))

# plt.figure(figsize=(10, 10))
# plt.imshow(transforms.ToPILImage()(sample))
# plt.show()

# THE RESIDUAL BLOCK
class ResidualBlock(nn.Module):

    def __init__(self, channels1,channels2,res_stride=1):
        super(ResidualBlock, self).__init__()
        self.inplanes=channels1
        # Exercise 1.1 construct the block (without shortcut -> Ex 1.3)
        # implement conv1 (which option for reshaping), batchnorm and conv2 (no reshaping)
        self.conv1 = nn.Conv2d(channels1, channels2, kernel_size=3, stride=res_stride, padding=1, bias=False)
        self.bn1 = nn.BatchNorm2d(channels2)
        self.conv2 = nn.Conv2d(channels2, channels2, kernel_size=3, stride=1, padding=1, bias=False)
        self.bn2 = nn.BatchNorm2d(channels2)  

        if res_stride != 1 or channels2 != channels1:
            # Exercise 1.3 the shortcut (supports resizing input during identity mapping)
            # create an nn.Sequential block with one 1x1 conv2D and one batchnorm
            # using res_stride to change spatial dimensions and channel 2 to change channel dimensions
            # again bias must be set to False
            self.shortcut=nn.Sequential(
                nn.Conv2d(channels1, channels2, kernel_size=1, stride=res_stride, bias=False),
                nn.BatchNorm2d(channels2)
            )
        else:
            self.shortcut=nn.Sequential()
            

    def forward(self, x):
        
        # forward pass: Conv2d > BatchNorm2d > ReLU > Conv2D >  BatchNorm2d > ADD > ReLU
        out=self.conv1(x)
        out=self.bn1(out)
        out = F.relu(out)
        out = self.conv2(out)
        out = self.bn2(out)
        # STUDENT TO Do - IMPLEMENT THE shortcut (1 line)
        out += self.shortcut(x)

        # final ReLu
        out = F.relu(out)

        return out

        
# THE RESNET
class ResNet(nn.Module):
    def __init__(self, block, num_blocks, num_strides, num_features, in_channels, num_classes, pool_kernel):
        super(ResNet, self).__init__()
        self.in_planes = num_features[0] #Â in_planes stores the number channels output from first convolution
        #STUDENT TO DO
        # step 1. Initialise the network with a 3 x3 conv and batch norm
        self.conv1 = nn.Conv2d(in_channels, num_features[0], kernel_size=3, stride=num_strides[0], padding=1, bias=False)
        self.bn1 = nn.BatchNorm2d(num_features[0])
        # Step 2: TO DO Using function make_layer() create 4 residual layers
        # num_blocks per layer is given by input argument num_blocks (which is an array)
        self.layer1 = self._make_layer(block, num_features[1], num_blocks, stride=num_strides[1])
        self.layer2 = self._make_layer(block, num_features[2], num_blocks, stride=num_strides[2])
        self.layer3 = self._make_layer(block, num_features[3], num_blocks, stride=num_strides[3])
        self.layer4 = self._make_layer(block, num_features[4], num_blocks, stride=num_strides[4])

        # MODIFYING CODE TO WORK WITH NON SQUARE IMAGES OF 240X320.
        # num_features does not affect the spatial dimension changes.
        # initial size is features,240,320
        # num_layers  = 4 
        # num_layers determines how many times the spatial dimensions will be halved.
        # after 4 layers, 240/2^(4-1) = 30 and 320/2^(4-1) = 40
        # Then average_pool2D reduces it to 7x10 when pool kernelsize is 4
        # average_pool2D reduces it to 15x20 when pool kernelsize is 2
        # Input to linear needs to be num_features[4]*7*10 when pool kernelsize is 4
        # Input to linear needs to be num_features[4]*15*20 when pool kernelsize is 2
        
        self.pool_kernel = pool_kernel
        num_layers = 4 
        # After layers
        # h_dim = (240)/(2**(num_layers-1))
        h_dim = (480)/(2**(num_layers-1))
        w_dim = (320)/(2**(num_layers-1) )

        # After average pooling
        h_dim = math.floor(h_dim/pool_kernel)
        w_dim = math.floor(w_dim/pool_kernel)

        # self.dropout = nn.Dropout(0.5)

        self.linear = nn.Linear(num_features[4]*h_dim*w_dim, num_classes)
        # For 3 layers -> below
        # self.linear = nn.Linear(num_features[3]*h_dim*w_dim, num_classes)


        # self.linear = nn.Linear(num_features[4], num_classes)


    def _make_layer(self, block, planes, num_blocks, stride):
        layers = []
        # create initial layer with option of downsampling and increase channels
        layers.append(block(self.in_planes, planes, stride))
        #Â then create num_blocks more for each group
        for i in np.arange(num_blocks):
            layers.append(block(planes, planes))
        
        # update class attribute in_planes which is keeping track of input channels
        self.in_planes = planes 
              
        return nn.Sequential(*layers) #Â return sequential object comining layers

    def forward(self, x):
      # initial convolution and batch norm
        out = F.relu(self.bn1(self.conv1(x)))
        # print('Shape after Conv: ', out.shape)
        #residual blocks 
        out = self.layer1(out)
        # print('Shape after 1st layer: ', out.shape)
        out = self.layer2(out)
        # print('Shape after 2nd layer: ', out.shape)
        out = self.layer3(out)
        # print('Shape after 3rd layer: ', out.shape)
        out = self.layer4(out)
        # print('Shape after 4th layer: ', out.shape)


        #average pool (flattens spatial dimensions)
        out = F.avg_pool2d(out, self.pool_kernel)
        # out = F.max_pool2d(out , self.pool_kernel)
        # out = F.avg_pool2d(out, 4)
        # print('Shape after average pool: ', out.shape)
        out = out.view(out.size(0), -1)   
        # print('Shape after view: ', out.shape)
        self.lin_dim = out.shape[1] 

        # Somewhere here --> add dropout. play around with different probabiliteies --> template : self.dropout = nn.Dropout(ï»¿0.25ï»¿)
        # out = self.dropout(out)

        out = self.linear(out)
        # print('Shape after linear: ', out.shape) 


        return out

# from albumentations.augmentations.transforms import ElasticTransform
# from albumentations.augmentations.transforms import 


# TRAINING THE RESNET IN BATCHES.

# PARAMETERS
fold = 1
features = 100
b_size = 8
epochs = 10
# num_features = [64,64,128,256,512]
# num_features = [32,32,64,128,256]
# num_features = [16,16,32,64,128]
num_features = [8,8,16,32,64]
# num_features = [4,4,8,16,32]

# Randomly sleect whether to transform or not. 
# Visualize some of the transformations.

albumentations_transform = albumentations.Compose([
    # albumentations.PiecewiseAffine(),
    # albumentations.augmentations.transforms.ElasticTransform(),
    albumentations.GaussNoise(),                                            
    albumentations.ElasticTransform(),
    albumentations.pytorch.transforms.ToTensor()
])

###############################################
import torch.optim as optim

# resnet = ResNet(ResidualBlock,2, [1,1,2,2,2], [64,64,128,256,512], in_channels= features , num_classes = 1, pool_kernel = 4 )
resnet = ResNet(ResidualBlock,2, [1,1,2,2,2], num_features , in_channels= features , num_classes = 1 , pool_kernel = 4 )

# Reduce the layers and reduce the layer features. make the net smaller.
# Augmentation?
# CLassiification maybe if regression doesnt work?
# use a amsller learning rate
# try dropout of the the FC linear layer maybe> AML notes for refernece.

resnet = resnet.to(device) 

# loss_fun = torch.nn.L1Loss()
loss_fun = torch.nn.SmoothL1Loss()
# loss_fun = torch.nn.MSELoss()

optimizer = torch.optim.SGD(resnet.parameters(), lr = 0.0001)

# optimizer = torch.optim.Adam(resnet.parameters() , lr = 0.0001)

# scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.1)

# optimizer = optim.SGD(resnet.parameters(), lr=0.001, momentum=0.9)
# optimizer = optim.Adam(resnet.parameters())
###############################################

# LOADING IN THE DATA USING THE DATALOADER CLASS.
train_dataset = TTVDataset(ttv = 0 , fold = fold ,features = features)
# train_dataset = TTVDataset(ttv = 0 , fold = fold ,features = features, transform = albumentations_transform)

test_dataset = TTVDataset(ttv = 1, fold = fold , features = features )
valid_dataset = TTVDataset(ttv = 2, fold = fold , features = features )

train_loader = torch.utils.data.DataLoader(train_dataset, batch_size = b_size , shuffle = True)
test_loader = torch.utils.data.DataLoader(test_dataset, batch_size = b_size , shuffle = True)
valid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size = b_size ,shuffle = True)

# No batches
# train_loader = torch.utils.data.DataLoader(train_dataset, batch_size= len(train_dataset) , shuffle = True)
# test_loader = torch.utils.data.DataLoader(test_dataset, batch_size= len(test_dataset) , shuffle = True)
# valid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size= len(valid_dataset) ,shuffle = True)

# Stores the losses for every batch.
training_loss = []
validation_loss = []

# Stores the mean loss of the batch iterations over different epochs.
mean_tr_loss_ep = []
mean_va_loss_ep = []

lrs = []

tr_running_loss = 0.0
va_running_loss = 0.0

cold_start = time.time()

path = '/content/drive/MyDrive/Colab Notebooks/2D CNN projections/Checkpoints/'
for epoch in range(epochs): 

  tr_loss_in_ep = []
  va_loss_in_ep = []
  
  descriptor = str(type(optimizer).__name__) + '_lr_'+ str(optimizer.param_groups[0]['lr']) + '_' +str(type(loss_fun).__name__)+'_fold_'+ str(fold) +'_feats_' + str(features) + '_epochs_' + str(epochs) + '_bsize_' + str(b_size)

  print('---------------TRAINING---------------')

  resnet.train()
  t0 = time.time()
  # enumerate can be used to output iteration index i, as well as the data 
  for i, (data, labels ) in enumerate(train_loader, 0):
  # for i, (data, labels , transform_time) in enumerate(train_loader, 0):

      data = data.to(device)
      labels = labels.to(device)

      # clear the gradient
      optimizer.zero_grad()

      #feed the input and acquire the output from network
      outputs = resnet(data)

      #calculating the predicted and the expected loss
      loss = loss_fun(outputs, labels)

      #compute the gradient
      loss.backward()

      #update the parameters
      optimizer.step()

      time_elapsed = time.time() - t0

      tr_loss = loss.item()

      training_loss.append(tr_loss)

      tr_running_loss += tr_loss

      tr_loss_in_ep.append(tr_loss)

      print('[{:d}/{:d}][{:d}/{:d}] Elapsed_time: {:.0f}m{:.0f}s LOSS: {:.4f}'
            .format(epoch+1, epochs, i+1, len(train_loader), time_elapsed // 60, time_elapsed % 60,
                    tr_loss))
  
  mean_tr_loss_ep.append(np.mean(tr_loss_in_ep))
  # lrs.append(optimizer.param_groups[0]["lr"])
  # CHANGING THE LEARNING RATE. 
  # scheduler.step()


  # # Checkpointing - Task 3.5.4
  torch.save({
          'epoch': epoch,
          'model_state_dict': resnet.state_dict(),
          'optimizer_state_dict': optimizer.state_dict(),
          'loss': loss,
          'b_size' : b_size,
          'num_features' : num_features,
          }, path+descriptor+'_model_ch.pt')

  t0 = time.time()

  print('---------------VALIDATION---------------')

  resnet.eval()
  with torch.no_grad():

    for j, (val_data, val_labels) in enumerate(valid_loader, 0):

        val_data = val_data.to(device)
        val_labels = val_labels.to(device)

        val_out = resnet(val_data)

        loss = loss_fun(val_out,val_labels)

        v_loss = loss.item()
        validation_loss.append(v_loss)

        va_running_loss += v_loss
        
        va_loss_in_ep.append(v_loss)

        time_elapsed = time.time() - t0

        print('[{:d}/{:d}][{:d}/{:d}] Elapsed_time: {:.0f}m{:.0f}s LOSS: {:.4f} '
          .format(epoch+1, epochs, j+1, len(valid_loader), time_elapsed // 60, time_elapsed % 60, v_loss))
        
  # va_loss_ep.append(va_running_loss/len(valid_loader))     
  mean_va_loss_ep.append(np.mean(va_loss_in_ep))

cold_delta =  time.time() - cold_start
print('TOTAL TIME TAKEN: {:.0f}m{:.0f}s '.format(cold_delta // 60 , cold_delta % 60))

# SAVING THE LOSSES ARRAYS
loss_dir = '/content/drive/MyDrive/Colab Notebooks/2D CNN projections/Losses/'

loss_dict = {
    'mean_tr_loss_ep' : mean_tr_loss_ep,
    'mean_va_loss_ep' : mean_va_loss_ep,
    'training_loss' : training_loss,
    'validation_loss' : validation_loss,
}

np.save(loss_dir+descriptor+'_loss',loss_dict)

# PLOTTING THE LOSSES

plot_dir = '/content/drive/MyDrive/Colab Notebooks/2D CNN projections/New Plots/'

print('Running Training Loss is: ',tr_running_loss)
print('Running Validation Loss is: ',va_running_loss)

plt.figure()
plt.plot(training_loss)
plt.title('Training loss over batches')
plt.ylabel('Loss')
plt.xlabel('Batch')

plt.figure()
plt.plot(range(1,epochs+1), mean_tr_loss_ep, '-o')
plt.title('Training loss over epochs')
plt.ylabel('Loss')
plt.xlabel('Epochs')

plt.figure()
plt.plot(validation_loss)
plt.title('Validation loss over batches')
plt.ylabel('Loss')
plt.xlabel('Batch')

plt.figure()
plt.plot(range(1,epochs+1), mean_va_loss_ep, '-o')
plt.title('Validation loss over epochs')
plt.ylabel('Loss')
plt.xlabel('Epochs')

plt.figure()
plt.plot(range(1,epochs+1), mean_tr_loss_ep,'-o')
plt.plot(range(1,epochs+1), mean_va_loss_ep,'-o')
plt.title('Loss over epochs')
plt.ylabel('Loss')
plt.xlabel('Epochs')
plt.legend(['Train','Valid'])
plt.savefig(plot_dir+descriptor+'_tr_va_eps.png')

# plt.figure()
# plt.plot(lrs, mean_tr_loss_ep,'-o')
# plt.plot(lrs, mean_va_loss_ep,'-o')
# plt.title('Loss over learning rate')
# plt.ylabel('Loss')
# plt.xlabel('LR')
# plt.legend(['Train','Valid'])

# plt.figure()
# plt.plot(lrs)
# plt.title('Learning rate over epochs')
# plt.ylabel('Learning Rate')
# plt.xlabel('Epoch')

# TESTING THE RESNET ON TEST SET
y_true = []
y_pred = [] 


for i, (data, labels) in enumerate(test_loader, 0):

  for j in range(labels.shape[0]):
    batch_l = labels.detach().numpy()
    batch_l = np.array(batch_l)
    y_true.append(batch_l[j][0])

  resnet.eval()
  with torch.no_grad():

    data = data.to(device)
    labels = labels.to(device)

    #feed the input and acquire the output from network
    outputs = resnet(data)

    for k in range(outputs.shape[0]):
      batch_p = outputs.cpu()
      batch_p = batch_p.detach().numpy()
      batch_p = np.array(batch_p)
      y_pred.append(batch_p[k][0])

from sklearn.metrics import r2_score

r2 = r2_score(y_true,y_pred)

print('R2 is: ', r2)
print('Corr is: ', np.sqrt(r2))

y_true = np.array(y_true)
y_pred = np.array(y_pred)

plt.figure()
plt.scatter(y_true,y_pred)
plt.plot([min(y_true),max(y_true)],[min(y_pred),max(y_pred)],'r', label = '$y=\hat{y}$') 
plt.title('R2: {:.4f}'.format(r2))
plt.xlabel('Target values') 
plt.ylabel('Predicted target values')
_=plt.legend(fontsize = 12)

# #  MODIFIED TO GO THROUGH BSIZE 1 TO 16 TRAINING THE RESNET IN BATCHES.

# # PARAMETERS
# fold = 1
# features = 100
# epochs = 10

# plot_dir = '/content/drive/MyDrive/Colab Notebooks/2D CNN projections/Plots/'
# loss_dir = '/content/drive/MyDrive/Colab Notebooks/2D CNN projections/Losses/'

# b_arr = [1,2,4,8,16]

# cold_start = time.time()

# r2_scores = []

# for b_size in b_arr:


#   ###############################################
#   import torch.optim as optim

#   resnet = ResNet(ResidualBlock,2, [1,1,2,2,2], [64,64,128,256,512], in_channels= features , num_classes = 1, pool_kernel = 4 )
#   # resnet = ResNet(ResidualBlock,2, [1,1,2,2,2], [32,64,64,128,256], in_channels= features , num_classes = 1 , pool_kernel = 2 )

#   resnet = resnet.to(device) 

#   loss_fun = torch.nn.L1Loss()

#   optimizer = optim.SGD(resnet.parameters(),lr = 0.001)
#   # optimizer = optim.SGD(resnet.parameters(), lr=0.001, momentum=0.9)
#   # optimizer = optim.Adam(resnet.parameters())
#   ###############################################


#   # LOADING IN THE DATA USING THE DATALOADER CLASS.
#   train_dataset = TTVDataset(ttv = 0 , fold = fold ,features = features)
#   test_dataset = TTVDataset(ttv = 1, fold = fold , features = features)
#   valid_dataset = TTVDataset(ttv = 2, fold = fold , features = features)

#   train_loader = torch.utils.data.DataLoader(train_dataset, batch_size = b_size , shuffle = True)
#   test_loader = torch.utils.data.DataLoader(test_dataset, batch_size = b_size , shuffle = True)
#   valid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size = b_size ,shuffle = True)

#   # No batches
#   # train_loader = torch.utils.data.DataLoader(train_dataset, batch_size= len(train_dataset) , shuffle = True)
#   # test_loader = torch.utils.data.DataLoader(test_dataset, batch_size= len(test_dataset) , shuffle = True)
#   # valid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size= len(valid_dataset) ,shuffle = True)

#   # Stores the losses for every batch.
#   training_loss = []
#   validation_loss = []

#   # Stores the mean loss of the batch iterations over different epochs.
#   mean_tr_loss_ep = []
#   mean_va_loss_ep = []

#   # tr_loss_ep = []
#   # va_loss_ep = []

#   tr_running_loss = 0.0
#   va_running_loss = 0.0


#   path = '/content/drive/MyDrive/Colab Notebooks/2D CNN projections/Checkpoints/'
#   for epoch in range(epochs): 

#     tr_loss_in_ep = []
#     va_loss_in_ep = []

#     print('---------------TRAINING---------------')

#     resnet.train()
#     t0 = time.time()
#     # enumerate can be used to output iteration index i, as well as the data 
#     for i, (data, labels) in enumerate(train_loader, 0):

#         data = data.to(device)
#         labels = labels.to(device)

#         # clear the gradient
#         optimizer.zero_grad()

#         #feed the input and acquire the output from network
#         outputs = resnet(data)

#         #calculating the predicted and the expected loss
#         loss = loss_fun(outputs, labels)

#         #compute the gradient
#         loss.backward()

#         #update the parameters
#         optimizer.step()

#         time_elapsed = time.time() - t0

#         tr_loss = loss.item()

#         training_loss.append(tr_loss)

#         tr_running_loss += tr_loss

#         tr_loss_in_ep.append(tr_loss)

#         print('[{:d}/{:d}][{:d}/{:d}] Elapsed_time: {:.0f}m{:.0f}s LOSS: {:.4f}'
#               .format(epoch+1, epochs, i+1, len(train_loader), time_elapsed // 60, time_elapsed % 60,
#                       tr_loss))
    
#     # tr_loss_ep.append(tr_running_loss/len(train_loader))

#     mean_tr_loss_ep.append(np.mean(tr_loss_in_ep))

#     descriptor = str(type(optimizer).__name__) + '_lr_'+ str(optimizer.param_groups[0]['lr']) + '_' +str(type(loss_fun).__name__)+'_fold_'+ str(fold) +'_feats_' + str(features) + '_epochs_' + str(epochs) + '_bsize_' + str(b_size)
#     # # Checkpointing - Task 3.5.4
#     torch.save({
#             'epoch': epoch,
#             'model_state_dict': resnet.state_dict(),
#             'optimizer_state_dict': optimizer.state_dict(),
#             'loss': loss,
#             }, path+descriptor+'_model_ch.pt')

#     t0 = time.time()

#     print('---------------VALIDATION---------------')

#     resnet.eval()
#     with torch.no_grad():

#       for j, (val_data, val_labels) in enumerate(valid_loader, 0):

#           val_data = val_data.to(device)
#           val_labels = val_labels.to(device)

#           val_out = resnet(val_data)

#           loss = loss_fun(val_out,val_labels)

#           v_loss = loss.item()
#           validation_loss.append(v_loss)

#           va_running_loss += v_loss
          
#           va_loss_in_ep.append(v_loss)

#           time_elapsed = time.time() - t0

#           print('[{:d}/{:d}][{:d}/{:d}] Elapsed_time: {:.0f}m{:.0f}s LOSS: {:.4f} '
#             .format(epoch+1, epochs, j+1, len(valid_loader), time_elapsed // 60, time_elapsed % 60, v_loss))
          
#     # va_loss_ep.append(va_running_loss/len(valid_loader))     
#     mean_va_loss_ep.append(np.mean(va_loss_in_ep))
  
#   plt.figure()
#   plt.plot(range(1,epochs+1), mean_tr_loss_ep,'-o')
#   plt.plot(range(1,epochs+1), mean_va_loss_ep,'-o')
#   plt.title('Loss over epochs')
#   plt.ylabel('Loss')
#   plt.xlabel('Epochs')
#   plt.legend(['Train','Valid'])
#   plt.savefig(plot_dir+descriptor+'_tr_va_eps.png')

#   np.save(loss_dir+descriptor+'_tr_loss',training_loss)
#   np.save(loss_dir+descriptor+'_va_loss',validation_loss)

#   np.save(loss_dir+descriptor+'_mean_tr_loss_ep',mean_tr_loss_ep)
#   np.save(loss_dir+descriptor+'_mean_va_loss_ep',mean_va_loss_ep)

#   # TESTING THE RESNET ON TEST SET
#   y_true = []
#   y_pred = [] 

#   for i, (data, labels) in enumerate(test_loader, 0):

#     for j in range(labels.shape[0]):
#       batch_l = labels.detach().numpy()
#       batch_l = np.array(batch_l)
#       y_true.append(batch_l[j][0])

#     resnet.eval()
#     with torch.no_grad():

#       data = data.to(device)
#       labels = labels.to(device)

#       #feed the input and acquire the output from network
#       outputs = resnet(data)

#       for k in range(outputs.shape[0]):
#         batch_p = outputs.cpu()
#         batch_p = batch_p.detach().numpy()
#         batch_p = np.array(batch_p)
#         y_pred.append(batch_p[k][0])

#   from sklearn.metrics import r2_score

#   r2 = r2_score(y_true,y_pred)

#   r2_scores.append(r2)

#   print('R2 is: ', r2)
#   print('Corr is: ', np.sqrt(r2))

# cold_delta =  time.time() - cold_start
# print('TOTAL TIME TAKEN: {:.0f}m{:.0f}s '.format(cold_delta // 60 , cold_delta % 60))

# # Trying to load in a saved model.

# # model = TheModelClass(*args, **kwargs)
# new_model = ResNet(ResidualBlock,2, [1,1,2,2,2], [64,64,128,256,512], in_channels= 110 , num_classes = 1, pool_kernel = 4 )

# import torch.optim as optim
# # optimizer = TheOptimizerClass(*args, **kwargs)
# new_optimizer = optim.SGD(new_model.parameters(),lr = 0.001)

# path = '/content/drive/MyDrive/Colab Notebooks/2D CNN projections/Checkpoints/'

# # checkpoint = torch.load(PATH)
# checkpoint = torch.load('/content/drive/MyDrive/Colab Notebooks/2D CNN projections/Checkpoints/SGD_lr_0.001_L1Loss_fold_1_feats_100_epochs_10_bsize_4_model_ch.pt')

# # model.load_state_dict(checkpoint['model_state_dict'])
# new_model.load_state_dict(checkpoint['model_state_dict'])

# new_optimizer.load_state_dict(checkpoint['optimizer_state_dict'])

# epoch = checkpoint['epoch']
# loss = checkpoint['loss']

# print(epoch)
# print(loss)

# # model.eval()
# # - or -
# # model.train()

# new_model.eval()
# new_model = new_model.to(device) 
# test_dataset = TTVDataset(ttv = 1, fold = 1 , features = 110)

# test_loader = torch.utils.data.DataLoader(test_dataset, batch_size = 4 , shuffle = True)

# # TESTING THE RESNET ON TEST SET
# y_true = []
# y_pred = [] 

# for i, (data, labels) in enumerate(test_loader, 0):

#   for j in range(labels.shape[0]):
#     batch_l = labels.detach().numpy()
#     batch_l = np.array(batch_l)
#     y_true.append(batch_l[j][0])

#   new_model.eval()
#   with torch.no_grad():

#     data = data.to(device)
#     labels = labels.to(device)

#     #feed the input and acquire the output from network
#     outputs = new_model(data)

#     for k in range(outputs.shape[0]):
#       batch_p = outputs.cpu()
#       batch_p = batch_p.detach().numpy()
#       batch_p = np.array(batch_p)
#       y_pred.append(batch_p[k][0])

# from sklearn.metrics import r2_score

# r2 = r2_score(y_true,y_pred)

# print('R2 is: ', r2)
# print('Corr is: ', np.sqrt(r2))

# # print(folder)

# loss_dir = '/content/drive/MyDrive/Colab Notebooks/2D CNN projections/Losses/'

# print(loss_dir+folder)

# # np.save('tr_loss',training_loss)

# # print(type(loss_fun).__name__)


# # print(type(optimizer).__name__)

# # print(optimizer.param_groups[0]['lr'])
# # print(lr_scheduler.get_lr())
# # print(print(optimizer.param_groups[0]['lr']))

# # LOADING IN SAVED LOSS ARRAYS

# loss_dir = '/content/drive/MyDrive/Colab Notebooks/2D CNN projections/Losses/'

# mean_tr_loss_ep =np.load(loss_dir+'SGD_lr_0.001_L1Loss_fold_1_feats_100_epochs_10_bsize_8_mean_tr_loss_ep.npy')

# mean_va_loss_ep =np.load(loss_dir+'SGD_lr_0.001_L1Loss_fold_1_feats_100_epochs_10_bsize_8_mean_va_loss_ep.npy')

# training_loss = np.load(loss_dir+'SGD_lr_0.001_L1Loss_epochs_5_bsize_1_tr_loss.npy')

# validation_loss = np.load(loss_dir+'SGD_lr_0.001_L1Loss_epochs_5_bsize_1_va_loss.npy')

# loss_dict = {
#     'mean_tr_loss_ep' : mean_tr_loss_ep,
#     'mean_va_loss_ep' : mean_va_loss_ep,
#     'training_loss' : training_loss,
#     'validation_loss' : validation_loss,
# }

# print(loss_dict['mean_tr_loss_ep'])

# # np.save(loss_dir+'testdict',loss_dict)

# # import pickle
# # saved_dict = pickle. load(loss_dir+'testdict.npy')
# saved_dict = np.load(loss_dir+'testdict.npy', allow_pickle=True)

# # print(saved_dict[()]['training_loss'].shape)
# # plt.figure(figsize=(12, 12))
# # plt.subplot(221)
# # plt.plot(training_loss)
# # plt.title('Training loss over batches')
# # plt.ylabel('Loss')
# # plt.xlabel('Batch')

# # plt.subplot(222)
# # plt.plot(validation_loss)
# # plt.title('Validation loss over batches')
# # plt.ylabel('Loss')
# # plt.xlabel('Batch')

# # plt.subplot(223)
# # plt.plot(range(1,5+1), mean_tr_loss_ep, '-o')
# # plt.title('Training loss over epochs')
# # plt.ylabel('Loss')
# # plt.xlabel('Epochs')


# # plt.subplot(224)
# # plt.plot(range(1,5+1), mean_va_loss_ep, '-o')
# # plt.title('Validation loss over epochs')
# # plt.ylabel('Loss')
# # plt.xlabel('Epochs')


# # plot_dir = '/content/drive/MyDrive/Colab Notebooks/2D CNN projections/Plots/'

# # descriptor = str(type(optimizer).__name__) + '_lr_'+ str(optimizer.param_groups[0]['lr']) + '_' +str(type(loss_fun).__name__) + '_epochs_' + str(epoch) + '_bsize_' + str(b_size)

# # print(descriptor)

# plt.figure()
# plt.plot(range(1,10+1), mean_tr_loss_ep,'-o')
# plt.plot(range(1,10+1), mean_va_loss_ep,'-o')
# plt.title('Loss over epochs' )
# plt.ylabel('Loss')
# plt.xlabel('Epochs')
# plt.legend(['Train','Valid'])

# # plt.savefig(plot_dir+'test_plot1')